{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\ndata = np.load('../input/train-1.npy')\ndata = np.vstack((data, np.load('../input/train-2.npy')))\ndata = np.vstack((data, np.load('../input/train-3.npy')))\ndata = np.vstack((data, np.load('../input/train-4.npy'))) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"width, height = 8, 8\n\nfig = plt.figure(figsize=(16, 20))\nfor n, (image, tag) in enumerate(data, 1):\n    if n > width * height:\n        break\n    plt.subplot(height, width, n)\n    plt.title(tag)\n    plt.imshow(image, cmap='gray')   \nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbe0362ee65afab03bf7f41e1b45792304771000"},"cell_type":"code","source":"import torch\nfrom torch import utils\nfrom torchvision import datasets, transforms\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom torch.autograd import Variable\nimport sys\nsys.path.append('../')\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\n\n%matplotlib inline\n        \ndef plot_graphs(log, epochs, title, tpe='loss'):\n    keys = log.keys()\n    logs = {k:[z for z in zip(*log[k])] for k in log.keys()}\n    epochs = {k:epochs for k in log.keys()}\n    #print(epochs)\n    if tpe == 'loss':\n        handlers, = zip(*[plt.plot(epochs[k], logs[k][0], label=k) for k in log.keys()])\n        plt.title(title + ', errors')\n        plt.xlabel('epoch')\n        plt.ylabel('error')\n        plt.legend(handles=handlers)\n        plt.show()\n    elif tpe == 'accuracy':\n        handlers, = zip(*[plt.plot(epochs[k], logs[k][1], label=k) for k in log.keys()])\n        plt.title(title + ', accuracy')\n        plt.xlabel('epoch')\n        plt.ylabel('accuracy')\n        plt.legend(handles=handlers)\n        plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fce17b36f1ab166b22a4a133d7ff5b1a85128cdb"},"cell_type":"code","source":"data_s = data.shape[0]\ntest_s = data_s // 5\ntrain_s = data_s - test_s\nx_train, x_test, y_train, y_test = train_test_split(data[:, 0], data[:, 1], test_size=test_s)  \nprint(x_train[1].shape, y_train.shape, x_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa82da6acb1161e9b6f66ec826b69810a4ffbb1e"},"cell_type":"code","source":"y_train = y_train.astype(np.long)\ny_test = y_test.astype(np.long)\nlables = np.unique(np.concatenate([y_test, y_train]))\nlables.sort()\nuni_to_class = {}\nclass_to_uni = {}\nfor i in range(1000):\n    uni_to_class[lables[i]] = i\n    class_to_uni[i] = lables[i]\ntarget_train = torch.zeros(train_s, dtype=torch.long)\ntarget_test = torch.zeros(test_s, dtype=torch.long)\nfor i in range(train_s):\n    target_train[i] = uni_to_class[y_train[i]]\nfor i in range(test_s):\n    target_test[i] = uni_to_class[y_test[i]]    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"176a629cb28a0a641b1370d5682eb71e58159d6c"},"cell_type":"code","source":"new_size = 48\n\ndef resize(img):\n    h, w  = img.shape\n    diff = abs(h - w)\n    vframe = np.ones((h, diff // 2)) * 255\n    hframe = np.ones((diff // 2, w)) * 255\n    if h > w:\n        img = np.hstack((vframe, img))\n        img = np.hstack((img, vframe))\n    else:\n        img = np.vstack((hframe, img))\n        img = np.vstack((img, hframe))\n    img = cv2.resize(img, (new_size, new_size))\n    img = torch.from_numpy(img.astype(np.float32))\n    return img    \n\n\ndef regularize(x):\n    mean = torch.mean(x, 0)\n    std = torch.std(x)\n    x -= mean\n    x /= std\n    return mean, std\n    \n#img = resize(img)\n#print(img)\n#print(img.shape)\nprint(x_test[0], x_test[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daec498dea758604a36456d0062a2492bc07f7ba"},"cell_type":"code","source":"for i in range(train_s):\n    x_train[i] = resize(x_train[i])\nfor i in range(test_s):\n    x_test[i] = resize(x_test[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ae5ea3f0c1e2db7c113f7ab079ae9e3be8fa76a"},"cell_type":"code","source":"class CNN2(torch.nn.Module):    \n    def __init__(self):\n        super(CNN2, self).__init__()\n        # batch_size x 1 x 48 x 48 \n        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2)\n        # batch_size x 16 x 48 x 48\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        #batch_size x 16 x 24 x 24\n        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = torch.nn.Conv2d(32, 48, kernel_size=3, stride=1, padding=1)\n        self.conv4 = torch.nn.Conv2d(48, 64, kernel_size=3, stride=1, padding=1)\n        # batch_size x 64 x 24 x 24\n        #pool\n        #batch_size x 64 x 12 x 12\n        self.fc1 = torch.nn.Linear(64 * 12 * 12, 2000)\n        self.fc2 = torch.nn.Linear(2000, 1000)\n        \n    def forward(self, x):\n        x = x.view(-1, 1, 48, 48)\n        x = F.leaky_relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.leaky_relu(self.conv2(x))\n        x = F.leaky_relu(self.conv3(x))\n        x = F.leaky_relu(self.conv4(x))\n        x = self.pool(x)\n        x = x.view(-1, 64 * 12 * 12)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5b3fea157d9ac49d4ecfe0df80805329abb86ae"},"cell_type":"code","source":"class CNN3(torch.nn.Module):    \n    def __init__(self):\n        super(CNN3, self).__init__()\n        # batch_size x 1 x 48 x 48 \n        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=7, stride=1, padding=3)\n        # batch_size x 16 x 48 x 48\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        #batch_size x 16 x 24 x 24\n        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n        #pool\n        # batch_size x 32 x 12 x 12\n        self.conv3 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        # batch_size x 64 x 12 x 12\n        #pool\n        #batch_size x 64 x 6 x 6\n        self.fc1 = torch.nn.Linear(64 * 6 * 6, 2000)\n        self.fc2 = torch.nn.Linear(2000, 1000)\n        \n    def forward(self, x):\n        x = x.view(-1, 1, 48, 48)\n        x = F.leaky_relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.leaky_relu(self.conv2(x))\n        x = self.pool(x)\n        x = F.leaky_relu(self.conv3(x))\n        x = self.pool(x)\n        x = x.view(-1, 64 * 6 * 6)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ee782c33b5d4beda9b097fcfee42169fefbae29"},"cell_type":"code","source":"class CNN4(torch.nn.Module):    \n    def __init__(self):\n        super(CNN4, self).__init__()\n        # batch_size x 1 x 48 x 48 \n        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=7, stride=1, padding=3)\n        # batch_size x 16 x 48 x 48\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        #batch_size x 16 x 24 x 24\n        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n        #pool\n        # batch_size x 32 x 12 x 12\n        self.conv3 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = torch.nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        self.conv5 = torch.nn.Conv2d(96, 128, kernel_size=3, stride=1, padding=1)\n        # batch_size x 128 x 12 x 12\n        #pool\n        #batch_size x 128 x 6 x 6\n        self.fc1 = torch.nn.Linear(128 * 6 * 6, 2000)\n        self.fc2 = torch.nn.Linear(2000, 1000)\n        \n    def forward(self, x):\n        x = x.view(-1, 1, 48, 48)\n        x = F.leaky_relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.leaky_relu(self.conv2(x))\n        x = self.pool(x)\n        x = F.leaky_relu(self.conv3(x))\n        x = F.leaky_relu(self.conv4(x))\n        x = F.leaky_relu(self.conv5(x))\n        x = self.pool(x)\n        x = x.view(-1, 128 * 6 * 6)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f865a2130d3713d3b92fa1c026050c04c9fe85c5"},"cell_type":"code","source":"class CNN5(torch.nn.Module):    \n    def __init__(self):\n        super(CNN5, self).__init__()\n        # batch_size x 1 x 48 x 48 \n        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=7, stride=1, padding=3)\n        # batch_size x 16 x 48 x 48\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        #batch_size x 16 x 24 x 24\n        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n        #pool\n        # batch_size x 32 x 12 x 12\n        self.conv3 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = torch.nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        self.conv5 = torch.nn.Conv2d(96, 128, kernel_size=3, stride=1, padding=1)\n        # batch_size x 128 x 12 x 12\n        self.fc1 = torch.nn.Linear(128 * 12 * 12, 2000)\n        self.fc2 = torch.nn.Linear(2000, 1000)\n        \n    def forward(self, x):\n        x = x.view(-1, 1, 48, 48)\n        x = F.leaky_relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.leaky_relu(self.conv2(x))\n        x = self.pool(x)\n        x = F.leaky_relu(self.conv3(x))\n        x = F.leaky_relu(self.conv4(x))\n        x = F.leaky_relu(self.conv5(x))\n        x = x.view(-1, 128 * 12 * 12)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6e73d2c339219e4c6f80391420231eb3c86a974"},"cell_type":"code","source":"x_train = torch.stack(x_train.tolist())\nx_test = torch.stack(x_test.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96eac7686d7bd3b265ccd6c851169d889ca71166"},"cell_type":"code","source":"mean, std = regularize(x_train)\nx_test -= mean\nx_test /= std\nprint(x_train.size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5d8d87f4a1bdd2de7f74bd803d1f7d827aeb51f"},"cell_type":"code","source":"l1_lmbd = 0.15\nl2_lmbd = 0.25\ndef li_loss(layer, i):\n    return torch.norm(layer.weight.data, p=i) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"accd6cd7808f7a9346870ce158ef7d8f6f10c444"},"cell_type":"code","source":"batch_s = 64\ndef train(model, epoch):\n    loss = 0\n    idx = 0\n    for i in range(train_s // batch_s):\n        data, target = x_train[idx : idx + batch_s], target_train[idx : idx + batch_s]\n        idx += batch_s    \n        optimizer.zero_grad()\n        data, target = data.cuda().float(), target.cuda().long()\n        output = model(data)\n        loss = F.cross_entropy(output, target) + l1_lmbd * li_loss(model.fc1, 1) \\\n        +  l1_lmbd * li_loss(model.fc2, 1) +  l2_lmbd * li_loss(model.fc1, 2) +  l2_lmbd * li_loss(model.fc2, 2)\n        #loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if i % 200 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, idx, len(x_train),\n                100. * idx / len(x_train), loss.data.item()))\n\n        \ndef test(model, log=None):\n    with torch.no_grad():\n        test_loss = 0\n        test_correct = 0\n        idx = 0\n        for i in range(test_s // batch_s):\n            data, target = x_test[idx : idx + batch_s], target_test[idx : idx + batch_s]\n            idx += batch_s\n            data, target = Variable(data), Variable(target)\n            data, target = data.cuda().float(), target.cuda().long()\n            output = model(data)\n            test_loss += F.cross_entropy(output, target, reduction='sum').data.item() \n            pred = output.data.max(1, keepdim=True)[1]\n            test_correct += pred.eq(target.data.view_as(pred)).sum()\n            test_loss /= train_s\n            test_correct_percent = 100. * test_correct / test_s\n\n        train_loss = 0\n        train_correct = 0\n        idx = 0\n        for i in range(train_s // batch_s):\n            data, target = x_train[idx : idx + batch_s], target_train[idx : idx + batch_s]\n            data, target = data.cuda().float(), target.cuda().long()\n            idx += batch_s\n            data, target = Variable(data), Variable(target)\n            output = model(data)\n            train_loss += F.cross_entropy(output, target, reduction='sum').data.item()\n            pred = output.data.max(1, keepdim=True)[1]\n            train_correct += pred.eq(target.data.view_as(pred)).sum()\n        train_loss /= train_s\n        train_correct_percent = 100. * train_correct / train_s\n    \n    print('\\nTest set:  Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n        test_loss, test_correct, test_s, test_correct_percent))\n    print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        train_loss, train_correct, train_s, train_correct_percent))\n    \n    log['test'].append((test_loss, test_correct_percent))\n    log['train'].append((train_loss, train_correct_percent))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c668f64bc6cc6373397cd51542eb4b032b8eedd"},"cell_type":"code","source":"def weights_init(model): \n    if type(model) == nn.Linear:\n        torch.nn.init.xavier_normal_(model.weight, gain=1.2)\n        model.bias.data.fill_(0.01)\n\n        \ndef train_n_test(model, title, epoc_num, train=train):\n    #model.apply(weights_init)\n    err_log = {'test': [], 'train': []}\n    epochs = range(1, epoc_num)\n    for epoch in epochs:\n        train(model, epoch)\n        print(\"epochs: \", epoch)\n        test(model, err_log)\n    plot_graphs(err_log, epochs, title, 'loss')\n    plot_graphs(err_log, epochs, title, 'accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64e00c84c35f29f79a66889c6803e6ccb7fb185f"},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel4 = CNN4().to(device)\noptimizer = optim.Adam(model4.parameters(), lr=0.0005)\ntrain_n_test(model4, \"Adam\", 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"746fbc0aa55f7f9b4ec7b90a2d3f7a502b984000"},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel5 = CNN5().to(device)\noptimizer = optim.Adam(model5.parameters(), lr=0.0005)\ntrain_n_test(model5, \"Adam\", 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46fb49255aa5fc6b0d53381a7a99435d32d2a184"},"cell_type":"code","source":"test_data = np.load('../input/test.npy')\ntest_data_s = len(test_data)\nprint(test_data[0].shape)\nfor i in range(test_data_s):\n    test_data[i] = resize(test_data[i])\ntest_data = torch.stack(test_data.tolist())\ntest_data -= mean\ntest_data /=std\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21c244b2feeca631c2fd802444409bbc269ecd72"},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\n\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"710a41d609e864d17f03ede8514fac8941c4c8c5"},"cell_type":"code","source":"import csv\n\ndef out(model, num):\n    with open('out' + num + '.csv', 'w') as out_file:\n        fieldnames = ['Id', 'Category']\n        wr = csv.DictWriter(out_file, fieldnames=fieldnames)\n        wr.writeheader()\n        with torch.no_grad():\n            idx = 0\n            for i in range(test_data_s // batch_s):\n                data_batch = test_data[idx : idx + batch_s]\n                data_batch = Variable(data_batch)\n                data_batch = data_batch.cuda()\n                output = model(data_batch)\n                pred = output.data.max(1, keepdim=True)[1]\n                for i in range(len(pred)):\n                    wr.writerow({'Id' : i + idx + 1 , 'Category' : class_to_uni[pred[i].item()]})\n                idx += batch_s\n            data_batch = test_data[idx : ]\n            data_batch = Variable(data_batch)\n            data_batch = data_batch.cuda()\n            output = model(data_batch)\n            pred = output.data.max(1, keepdim=True)[1]\n            for i in range(len(pred)):\n                wr.writerow({'Id' : i + idx + 1 , 'Category' : class_to_uni[pred[i].item()]})\n    #create_download_link(out_file)            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a25fdbc24577f8bfad55fccb08319c4aebbdc7b"},"cell_type":"code","source":"out(model4, '4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fad7e3456ba808c6c5b0c86507db1561e70b0b41"},"cell_type":"code","source":"out(model5, '5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}